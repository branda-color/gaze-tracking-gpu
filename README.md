# åŸºæ–¼åç§»åˆ†è§£èˆ‡æ³¨æ„åŠ›æ©Ÿåˆ¶çš„å¤–è§€å¼è¦–ç·šä¼°è¨ˆç ”ç©¶

æœ¬å°ˆæ¡ˆæ”¹è‰¯è‡ªè«–æ–‡ [Chen et al. (WACV 2020)](https://doi.org/10.1109/WACV45572.2020.9093419)ï¼Œä¸¦èåˆ [pperle çš„å¯¦ä½œ](https://github.com/pperle/gaze-tracking)é€²è¡Œå„ªåŒ–èˆ‡æ“´å……ã€‚

---

## âœ… Model

- æ•´åˆ SELayerã€LeakyReLU èˆ‡ Subject Bias æ¨¡çµ„ï¼Œæå‡æ¨¡å‹ç‰¹å¾µæ„ŸçŸ¥èƒ½åŠ›èˆ‡è¨“ç·´ç©©å®šæ€§  
- æ¶æ§‹æ”¯æ´å¤šæ¨¡æ…‹ç‰¹å¾µèåˆï¼ˆè‡‰éƒ¨ï¼‹é›™çœ¼ï¼‰ï¼Œå¢å¼·è¦–ç·šä¼°è¨ˆç²¾åº¦èˆ‡ç©©å®šæ€§  
- MLP å»ºæ§‹ä¹‹å€‹é«”åç§»æ¨¡çµ„ `bias_mlp(i)` å¯ä¾ä½¿ç”¨è€… ID å‹•æ…‹ç”¢ç”Ÿåå·®å‘é‡ï¼Œå¼·åŒ–å€‹äººåŒ–æ ¡æ­£æ•ˆæœ  
- æ¨¡å‹æ–¼ MPIIFaceGaze æ¸¬è©¦ä¸‹ï¼Œåœ¨å°‘æ¨£æœ¬æ¢ä»¶ï¼ˆS=1ï¼‰ä»èƒ½ç¶­æŒ 2.9Â° çš„èª¤å·®è¡¨ç¾  
- æå‡éƒ¨ç½²å½ˆæ€§ï¼Œé©ç”¨æ–¼è¡Œå‹•è£ç½®ã€äººæ©Ÿäº’å‹•ã€æ™ºæ…§ç›£æ§ç­‰å¯¦å‹™å ´æ™¯  

---

## ğŸ“¦ Data

- é¸ç”¨ [MPIIFaceGaze](https://www.perceptualui.org/research/datasets/MPIIFaceGaze/) ä½œç‚ºä¸»è¦è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™é›†  
- è‡ªå‹•éæ¿¾ gaze target è½åœ¨è¢å¹•å¯è¦–ç¯„åœå¤–çš„æ¨£æœ¬  
- æ’é™¤æ¥µç«¯å€¼èˆ‡ç„¡æ•ˆæ¨™è¨»ï¼Œæå‡æ¨¡å‹è¨“ç·´ç©©å®šæ€§èˆ‡æ³›åŒ–èƒ½åŠ›  
- å¯¦éš›æ’é™¤æ¯”ä¾‹ç´„ 7%  

---

## ğŸ¯ Calibration

- æ¡ç”¨ Eq.3 æ ¡æ­£ç­–ç•¥ï¼šé¸å®šå–®ä¸€æ³¨è¦–é»ï¼Œè¨ˆç®—å¹³å‡ gaze èª¤å·®å‘é‡ <img width="194" height="39" alt="è¢å¹•æ“·å–ç•«é¢ 2025-03-31 155814" src="https://github.com/user-attachments/assets/8ed62aa7-bc7e-47ea-b44b-980885fc559e" />
ï¼Œè£œå„Ÿæ¨¡å‹é æ¸¬åå·®  
- å¯¦ä½œ `evaluate_with_eq3()`ï¼Œæ”¯æ´å¤šæ¨£æœ¬æ ¡æ­£ï¼ˆS=1, 5, 9, 16ï¼‰ä¸¦è¼¸å‡ºæ ¡æ­£å¾Œèª¤å·®  
- æ¨¡å‹å…§å»ºåç§»è£œå„Ÿæ¨¡çµ„ `bias_mlp(i)`ï¼šæ–¼è¨“ç·´éšæ®µæ ¹æ“š person_idx å­¸ç¿’å€‹é«”åŒ–åç§»  
- æä¾›é›™æ¨¡çµ„æ¯”è¼ƒï¼šEq.3 æ‰‹å‹•å¾Œæ ¡æ­£ vs æ¨¡å‹å…§å»ºå‹•æ…‹åç§»è£œå„Ÿ  
- `compute_bias_eq3()` è‡ªå‹•æŒ‘é¸æ ¡æ­£æ¨£æœ¬ï¼Œè¨ˆç®—æ ¡æ­£å‘é‡  

---

## ğŸ“ˆ Evaluation

- è©•ä¼°æŒ‡æ¨™ï¼šAngular Errorï¼ˆå–®ä½ï¼šåº¦ï¼‰  
<img width="374" height="100" alt="è¢å¹•æ“·å–ç•«é¢ 2025-03-25 144035" src="https://github.com/user-attachments/assets/e8d27d61-e581-4bf6-94d2-beb3929acd8d" />  
- é æ¸¬å€¼ç‚º [pitch, yaw]ï¼Œéœ€å…ˆè½‰æ›ç‚º 3D gaze vector  
- Ground Truth å‘é‡ç‚ºç”±è³‡æ–™æ¨™è¨»è½‰æ›æ‰€å¾—çš„å–®ä½ gaze vector  
- `eval.ipynb` æä¾›å®Œæ•´è©•ä¼°æµç¨‹ï¼Œå¯é‡å°ä¸åŒ S å€¼åŸ·è¡Œæ ¡æ­£å¾Œæ¸¬è©¦  
- å¯ä½¿ç”¨ `plot_prediction_vs_ground_truth()` å‡½æ•¸è¦–è¦ºåŒ– pitch/yaw é æ¸¬èˆ‡æ¨™è¨»å·®ç•°  

---
## Bibliography
[1] Zhaokang Chen and Bertram E. Shi, â€œAppearance-based gaze estimation using dilated-convolutionsâ€, Lecture Notes in Computer Science, vol. 11366, C. V. Jawahar, Hongdong Li, Greg Mori, and Konrad Schindler, Eds., pp. 309â€“324, 2018. DOI: 10.1007/978-3-030-20876-9_20. [Online]. Available: https://doi.org/10.1007/978-3-030-20876-9_20. \
[2] â€”â€”, â€œOffset calibration for appearance-based gaze estimation via gaze decompositionâ€, in IEEE Winter Conference on Applications of Computer Vision, WACV 2020, Snowmass Village, CO, USA, March 1-5, 2020, IEEE, 2020, pp. 259â€“268. DOI: 10.1109/WACV45572.2020.9093419. [Online]. Available: https://doi.org/10.1109/WACV45572.2020.9093419. \
[3] Tobias Fischer, Hyung Jin Chang, and Yiannis Demiris, â€œRT-GENE: real-time eye gaze estimation in natural environmentsâ€, in Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part X, Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, Eds., ser. Lecture Notes in Computer Science, vol. 11214, Springer, 2018, pp. 339â€“357. DOI: 10.1007/978-3-030-01249-6_21. [Online]. Available: https://doi.org/10.1007/978-3-030-01249-6_21. \
[4] Erik LindÃ©n, Jonas SjÃ¶strand, and Alexandre ProutiÃ¨re, â€œLearning to personalize in appearance-based gaze trackingâ€, pp. 1140â€“1148, 2019. DOI: 10.1109/ICCVW.2019.00145. [Online]. Available: https://doi.org/10.1109/ICCVW.2019.00145.  \
[5] Gang Liu, Yu Yu, Kenneth Alberto Funes Mora, and Jean-Marc Odobez, â€œA differential approach for gaze estimation with calibrationâ€, in British Machine Vision Conference 2018, BMVC 2018, Newcastle, UK, September 3-6, 2018, BMVA Press, 2018, p. 235. [Online]. Available: http://bmvc2018.org/contents/papers/0792.pdf. \
[6] Seonwook Park, Shalini De Mello, Pavlo Molchanov, Umar Iqbal, Otmar Hilliges, and Jan Kautz, â€œFew-shot adaptive gaze estimationâ€, pp. 9367â€“9376, 2019. DOI: 10.1109/ICCV.2019.00946. [Online]. Available: https://doi.org/10.1109/ICCV.2019.00946. \
[7] Seonwook Park, Xucong Zhang, Andreas Bulling, and Otmar Hilliges, â€œLearning to find eye region landmarks for remote gaze estimation in unconstrained settingsâ€, Bonita Sharif and Krzysztof Krejtz, Eds., 21:1â€“21:10, 2018. DOI: 10.1145/3204493.3204545. [Online]. Available: https://doi.org/10.1145/3204493.3204545. \
[8] Yu Yu, Gang Liu, and Jean-Marc Odobez, â€œImproving few-shot user-specific gaze adaptation via gaze redirection synthesisâ€, pp. 11 937â€“11 946, 2019. DOI: 10.1109/CVPR.2019.01221. [Online]. Available: http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Improving_Few-Shot_User-Specific_Gaze_Adaptation_via_Gaze_Redirection_Synthesis_CVPR_2019_paper.html. \
[9] Xucong Zhang, Yusuke Sugano, Mario Fritz, and Andreas Bulling, â€œItâ€™s written all over your face: Full-face appearance-based gaze estimationâ€, pp. 2299â€“2308, 2017. DOI: 10.1109/CVPRW.2017.284. [Online]. Available: https://doi.org/10.1109/CVPRW.2017.284 \
[10] â€”â€”, â€œMpiigaze: Real-world dataset and deep appearance-based gaze estimationâ€, IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 1, pp. 162â€“175, 2019. DOI: 10.1109/TPAMI.2017.2778103. [Online]. Available: https://doi.org/10.1109/TPAMI.2017.2778103. \
