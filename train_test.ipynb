{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc492cb8-49f3-4e6e-91e9-532633157520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 檢查系統中是否有可用的 CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4b98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.21 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "from argparse import ArgumentParser\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT, EPOCH_OUTPUT\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from dataset.mpii_face_gaze_dataset import get_dataloaders\n",
    "from model import FinalModel\n",
    "from utils import calc_angle_error, PitchYaw, plot_prediction_vs_ground_truth, log_figure, get_random_idx, get_each_of_one_grid_idx\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aabf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(FinalModel):\n",
    "    def __init__(self, learning_rate: float = 0.001, weight_decay: float = 0., k=None, adjust_slope: bool = False, grid_calibration_samples: bool = False, *args, **kwargs):\n",
    "        print(\"Initializing train Model...\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        print(\"train Model base (FinalModel) initialized.\")\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.k = [9, 128] if k is None else k\n",
    "        self.adjust_slope = adjust_slope\n",
    "        self.grid_calibration_samples = grid_calibration_samples\n",
    "\n",
    "        self.save_hyperparameters()  # log hyperparameters\n",
    "\n",
    "        print(\"train Model initialization completed.\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "    def __step(self, batch: dict) -> Tuple:\n",
    "        \"\"\"\n",
    "        Operates on a single batch of data.\n",
    "\n",
    "        :param batch: The output of your :class:`~torch.utils.data.DataLoader`. A tensor, tuple or list.\n",
    "        :return: calculated loss, given values and predicted outputs\n",
    "        \"\"\"\n",
    "        person_idx = batch['person_idx'].long()\n",
    "        left_eye_image = batch['left_eye_image'].float()\n",
    "        right_eye_image = batch['right_eye_image'].float()\n",
    "        full_face_image = batch['full_face_image'].float()\n",
    "\n",
    "        gaze_pitch = batch['gaze_pitch'].float()\n",
    "        gaze_yaw = batch['gaze_yaw'].float()\n",
    "\n",
    "        #print(\"gaze_pitch:\", gaze_pitch)\n",
    "        #print(\"gaze_yaw:\", gaze_yaw)\n",
    "        \n",
    "        labels = torch.stack([gaze_pitch, gaze_yaw]).T\n",
    "\n",
    "        outputs = self(person_idx, full_face_image, right_eye_image, left_eye_image)  # prediction on the base model\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "\n",
    "        return loss, labels, outputs\n",
    "\n",
    "    def training_step(self, train_batch: dict, batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss, labels, outputs = self.__step(train_batch)\n",
    "\n",
    "        self.log('train/loss', loss)\n",
    "        self.log('train/angular_error', calc_angle_error(labels, outputs))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, valid_batch: dict, batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss, labels, outputs = self.__step(valid_batch)\n",
    "\n",
    "        self.log('valid/offset(k=0)/loss', loss)\n",
    "        self.log('valid/offset(k=0)/angular_error', calc_angle_error(labels, outputs))\n",
    "\n",
    "\n",
    "        return {'loss': loss, 'labels': labels, 'outputs': outputs, 'gaze_locations': valid_batch['gaze_location'], 'screen_sizes': valid_batch['screen_size']}\n",
    "\n",
    "    def validation_epoch_end(self, outputs: EPOCH_OUTPUT) -> None:\n",
    "        self.__log_and_plot_details(outputs, 'epoch_end_valid')\n",
    "\n",
    "    def test_step(self, test_batch: dict, batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss, labels, outputs = self.__step(test_batch)\n",
    "\n",
    "        self.log('test/offset(k=0)/loss', loss,on_epoch=True, prog_bar=True)\n",
    "        self.log('test/offset(k=0)/angular_error', calc_angle_error(labels, outputs))\n",
    "\n",
    "        return {'loss': loss, 'labels': labels, 'outputs': outputs, 'gaze_locations': test_batch['gaze_location'], 'screen_sizes': test_batch['screen_size']}\n",
    "\n",
    "    def test_epoch_end(self, outputs: EPOCH_OUTPUT) -> None:\n",
    "        self.__log_and_plot_details(outputs, 'epoch_end_test')\n",
    "\n",
    "    def __log_and_plot_details(self, outputs, tag: str):\n",
    "        test_labels = torch.cat([output['labels'] for output in outputs])\n",
    "        test_outputs = torch.cat([output['outputs'] for output in outputs])\n",
    "        test_gaze_locations = torch.cat([output['gaze_locations'] for output in outputs])\n",
    "        test_screen_sizes = torch.cat([output['screen_sizes'] for output in outputs])\n",
    "\n",
    "        figure = plot_prediction_vs_ground_truth(test_labels, test_outputs, PitchYaw.PITCH)\n",
    "        log_figure(self.logger, f'{tag}/offset(k=0)/pitch', figure, self.global_step)\n",
    "\n",
    "        figure = plot_prediction_vs_ground_truth(test_labels, test_outputs, PitchYaw.YAW)\n",
    "        log_figure(self.logger, f'{tag}/offset(k=0)/yaw', figure, self.global_step)\n",
    "\n",
    "        # find calibration params\n",
    "         # 確保 last_x 合理\n",
    "        last_x = min(500, len(test_labels))\n",
    "        calibration_train = test_outputs[:-last_x].cpu().detach().numpy()\n",
    "        calibration_test = test_outputs[-last_x:].cpu().detach().numpy()\n",
    "        calibration_train_labels = test_labels[:-last_x].cpu().detach().numpy()\n",
    "        calibration_test_labels = test_labels[-last_x:].cpu().detach().numpy()\n",
    "\n",
    "        # 日誌檢查\n",
    "        print(f\"日誌檢查開始\")\n",
    "        print(f\"test_labels shape: {test_labels.shape}\")\n",
    "        print(f\"last_x: {last_x}\")\n",
    "        print(f\"calibration_train_labels shape: {calibration_train_labels.shape}\")\n",
    "        print(f\"calibration_train shape: {calibration_train.shape}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # 檢查切片後的結果是否為空##############################################################\n",
    "\n",
    "        # 檢查 calibration_train_labels 是否為空\n",
    "        if calibration_train_labels.size == 0:\n",
    "            print(\"Warning: calibration_train_labels is empty! Skipping this batch.\")\n",
    "            return\n",
    "\n",
    "\n",
    "        ######################################################################################\n",
    "        gaze_locations_train = test_gaze_locations[:-last_x].cpu().detach().numpy()\n",
    "        screen_sizes_train = test_screen_sizes[:-last_x].cpu().detach().numpy()\n",
    "\n",
    "        if len(calibration_train) > 0:\n",
    "            for k in self.k:\n",
    "                if k <= 0:\n",
    "                    continue\n",
    "                calibrated_solutions = []\n",
    "\n",
    "                num_calibration_runs = 500 if self.grid_calibration_samples else 10_000  # original results are both evaluated with 10,000 runs\n",
    "                for calibration_run_idx in range(num_calibration_runs):  # get_each_of_one_grid_idx is slower than get_random_idx\n",
    "                    np.random.seed(42 + calibration_run_idx)\n",
    "                    calibration_sample_idxs = get_each_of_one_grid_idx(k, gaze_locations_train, screen_sizes_train) if self.grid_calibration_samples else get_random_idx(k, len(calibration_train))\n",
    "\n",
    "                    #####################################################################\n",
    "                    ###加判斷\n",
    "                    #######################################################################\n",
    "                    # 確保索引不會超出範圍\n",
    "                    if not calibration_sample_idxs:\n",
    "                        print(f\"Warning: No valid calibration sample indices for k={k}. Skipping this iteration.\")\n",
    "                        continue\n",
    "               \n",
    "                    #######################################################################\n",
    "\n",
    "                    \n",
    "                    calibration_points_x = np.asarray([calibration_train[idx] for idx in calibration_sample_idxs])\n",
    "                    calibration_points_y = np.asarray([calibration_train_labels[idx] for idx in calibration_sample_idxs])\n",
    "\n",
    "                     #####################################################################\n",
    "                    ###加判斷\n",
    "                    #######################################################################\n",
    "\n",
    "                    # 檢查 calibration_points 是否為空\n",
    "                    if calibration_points_x.size == 0 or calibration_points_y.size == 0:\n",
    "                        print(f\"Warning: Empty calibration points for k={k}. Skipping this iteration.\")\n",
    "                        continue\n",
    "\n",
    "                     #####################################################################\n",
    "            \n",
    "\n",
    "                    if self.adjust_slope:\n",
    "                        m, b = np.polyfit(calibration_points_y[:, :1].reshape(-1), calibration_points_x[:, :1].reshape(-1), deg=1)\n",
    "                        pitch_fixed = (calibration_test[:, :1] - b) * (1 / m)\n",
    "                        m, b = np.polyfit(calibration_points_y[:, 1:].reshape(-1), calibration_points_x[:, 1:].reshape(-1), deg=1)\n",
    "                        yaw_fixed = (calibration_test[:, 1:] - b) * (1 / m)\n",
    "                    else:\n",
    "                        mean_diff_pitch = (calibration_points_y[:, :1] - calibration_points_x[:, :1]).mean()  # mean offset\n",
    "                        pitch_fixed = calibration_test[:, :1] + mean_diff_pitch\n",
    "                        mean_diff_yaw = (calibration_points_y[:, 1:] - calibration_points_x[:, 1:]).mean()  # mean offset\n",
    "                        yaw_fixed = calibration_test[:, 1:] + mean_diff_yaw\n",
    "\n",
    "                    pitch_fixed, yaw_fixed = torch.Tensor(pitch_fixed), torch.Tensor(yaw_fixed)\n",
    "                    outputs_fixed = torch.stack([pitch_fixed, yaw_fixed], dim=1).squeeze(-1)\n",
    "                    calibrated_solutions.append(calc_angle_error(torch.Tensor(calibration_test_labels), outputs_fixed).item())\n",
    "\n",
    "            #####################################################################\n",
    "            ###加判斷\n",
    "            #######################################################################\n",
    "                if calibrated_solutions:\n",
    "                    self.log(f'{tag}/offset(k={k})/mean_angular_error', np.asarray(calibrated_solutions).mean())\n",
    "                    self.log(f'{tag}/offset(k={k})/std_angular_error', np.asarray(calibrated_solutions).std())\n",
    "                else:\n",
    "                    print(f\"Warning: No calibrated solutions generated for k={k}.\")\n",
    "\n",
    "         #######################################################################\n",
    "\n",
    "        # best case, with all calibration samples, all values except the last `last_x` values\n",
    "        if self.adjust_slope:\n",
    "            m, b = np.polyfit(calibration_train_labels[:, :1].reshape(-1), calibration_train[:, :1].reshape(-1), deg=1)\n",
    "            pitch_fixed = torch.Tensor((calibration_test[:, :1] - b) * (1 / m))\n",
    "            m, b = np.polyfit(calibration_train_labels[:, 1:].reshape(-1), calibration_train[:, 1:].reshape(-1), deg=1)\n",
    "            yaw_fixed = torch.Tensor((calibration_test[:, 1:] - b) * (1 / m))\n",
    "        else:\n",
    "            mean_diff_pitch = (calibration_train_labels[:, :1] - calibration_train[:, :1]).mean()  # mean offset\n",
    "            pitch_fixed = calibration_test[:, :1] + mean_diff_pitch\n",
    "            mean_diff_yaw = (calibration_train_labels[:, 1:] - calibration_train[:, 1:]).mean()  # mean offset\n",
    "            yaw_fixed = calibration_test[:, 1:] + mean_diff_yaw\n",
    "\n",
    "        pitch_fixed, yaw_fixed = torch.Tensor(pitch_fixed), torch.Tensor(yaw_fixed)\n",
    "        outputs_fixed = torch.stack([pitch_fixed, yaw_fixed], dim=1).squeeze(-1)\n",
    "        calibration_test_labels = torch.Tensor(calibration_test_labels)\n",
    "        self.log(f'{tag}/offset(k=all)/angular_error', calc_angle_error(calibration_test_labels, outputs_fixed))\n",
    "\n",
    "        figure = plot_prediction_vs_ground_truth(calibration_test_labels, outputs_fixed, PitchYaw.PITCH)\n",
    "        log_figure(self.logger, f'{tag}/offset(k=all)/pitch', figure, self.global_step)\n",
    "\n",
    "        figure = plot_prediction_vs_ground_truth(calibration_test_labels, outputs_fixed, PitchYaw.YAW)\n",
    "        log_figure(self.logger, f'{tag}/offset(k=all)/yaw', figure, self.global_step)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef30cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_to_data: str, validate_on_person: int, test_on_person: int, learning_rate: float, weight_decay: float, batch_size: int, k: int, adjust_slope: bool, grid_calibration_samples: bool):\n",
    "    seed_everything(42)\n",
    "\n",
    "    model = Model(learning_rate, weight_decay, k, adjust_slope, grid_calibration_samples)\n",
    "\n",
    "    # 確保保存模型的目錄存在(變成eval要的型態資料夾)\n",
    "    base_model_dir = './saved_models/'\n",
    "    os.makedirs(base_model_dir, exist_ok=True)\n",
    "    person_model_dir = os.path.join(base_model_dir, f'p{validate_on_person:02d}')\n",
    "    os.makedirs(person_model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # 設定模型保存\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=person_model_dir,  # 保存模型的目錄\n",
    "        filename=f'p{validate_on_person:02d}_best',  # 保存文件的名稱\n",
    "        save_top_k=1,  # 只保存最好的模型\n",
    "        verbose=True,\n",
    "        monitor='valid/offset(k=0)/loss',  # 根據某個監控指標保存，比如 validation loss\n",
    "        mode='min'  # 以最小化 val_loss 的方式保存最好的模型\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        gpus=1,\n",
    "        max_epochs=1,\n",
    "        fast_dev_run=False,\n",
    "        default_root_dir=person_model_dir,\n",
    "        logger=[\n",
    "            TensorBoardLogger(save_dir=f\"tb_logs/p{validate_on_person:02d}\"),\n",
    "        ],\n",
    "        benchmark=True,\n",
    "        callbacks=[checkpoint_callback],  # 傳入模型保存回調\n",
    "\n",
    "        ######禁用檢查要開才能印出model的print\n",
    "        #num_sanity_val_steps=0,\n",
    "        #limit_val_batches=0,  # 禁用验证数据检查\n",
    "        #enable_progress_bar=True,  # 确保显示标准输出\n",
    "        #log_every_n_steps=1\n",
    "    )\n",
    "\n",
    "    print(\"Start data loading...\")\n",
    "    train_dataloader, valid_dataloader, test_dataloader = get_dataloaders(path_to_data, validate_on_person, test_on_person, batch_size)\n",
    "\n",
    "    print(\"Data loading complete.\")\n",
    "  \n",
    "    trainer.fit(model, train_dataloader, valid_dataloader)\n",
    "    trainer.test(model, test_dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1baa9c-aaec-4ef0-9f33-b20c3b96bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing train Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Model base (FinalModel) initialized.\n",
      "train Model initialization completed.\n",
      "Start data loading...\n",
      "train on persons [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "valid on person 0\n",
      "test on person 1\n",
      "len(dataset_train) 60784\n",
      "len(dataset_valid) 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | cnn_face     | Sequential | 683 K \n",
      "1 | cnn_eye      | Sequential | 564 K \n",
      "2 | fc_face      | Sequential | 1.2 M \n",
      "3 | cnn_eye2fc   | Sequential | 904 K \n",
      "4 | fc_eye       | Sequential | 1.6 M \n",
      "5 | fc_eyes_face | Sequential | 148 K \n",
      "--------------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.289    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset_test) 2904\n",
      "Data loading complete.\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.27s/it]日誌檢查開始\n",
      "test_labels shape: torch.Size([64, 2])\n",
      "last_x: 64\n",
      "calibration_train_labels shape: (0, 2)\n",
      "calibration_train shape: (0, 2)\n",
      "Warning: calibration_train_labels is empty! Skipping this batch.\n",
      "Epoch 0:  95%|█████████▌| 1899/1990 [03:08<00:09, 10.06it/s, loss=0.0226, v_num=29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/91 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/91 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|          | 1/91 [00:00<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 1900/1990 [03:14<00:09,  9.78it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1901/1990 [03:14<00:09,  9.78it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:   3%|▎         | 3/91 [00:00<00:08, 10.16it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1902/1990 [03:14<00:08,  9.78it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1903/1990 [03:14<00:08,  9.79it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:   5%|▌         | 5/91 [00:00<00:06, 13.26it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1904/1990 [03:14<00:08,  9.79it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1905/1990 [03:14<00:08,  9.79it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1906/1990 [03:14<00:08,  9.80it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:   9%|▉         | 8/91 [00:00<00:05, 16.22it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1907/1990 [03:14<00:08,  9.80it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1908/1990 [03:14<00:08,  9.80it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1909/1990 [03:14<00:08,  9.80it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  12%|█▏        | 11/91 [00:00<00:04, 17.82it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1910/1990 [03:14<00:08,  9.81it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1911/1990 [03:14<00:08,  9.81it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  14%|█▍        | 13/91 [00:00<00:04, 18.31it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1912/1990 [03:14<00:07,  9.81it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1913/1990 [03:14<00:07,  9.81it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▌| 1914/1990 [03:14<00:07,  9.82it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  18%|█▊        | 16/91 [00:00<00:03, 18.85it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 1915/1990 [03:15<00:07,  9.82it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▋| 1916/1990 [03:15<00:07,  9.82it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  20%|█▉        | 18/91 [00:01<00:03, 19.08it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 1917/1990 [03:15<00:07,  9.82it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▋| 1918/1990 [03:15<00:07,  9.83it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  22%|██▏       | 20/91 [00:01<00:03, 18.94it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 1919/1990 [03:15<00:07,  9.83it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  96%|█████████▋| 1920/1990 [03:15<00:07,  9.83it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  24%|██▍       | 22/91 [00:01<00:03, 18.95it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1921/1990 [03:15<00:07,  9.83it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1922/1990 [03:15<00:06,  9.84it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1923/1990 [03:15<00:06,  9.84it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  27%|██▋       | 25/91 [00:01<00:03, 19.36it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1924/1990 [03:15<00:06,  9.84it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1925/1990 [03:15<00:06,  9.84it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  30%|██▉       | 27/91 [00:01<00:03, 19.52it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1926/1990 [03:15<00:06,  9.85it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1927/1990 [03:15<00:06,  9.85it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  32%|███▏      | 29/91 [00:01<00:03, 17.88it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1928/1990 [03:15<00:06,  9.85it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1929/1990 [03:15<00:06,  9.85it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  34%|███▍      | 31/91 [00:01<00:03, 18.05it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1930/1990 [03:15<00:06,  9.85it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1931/1990 [03:15<00:05,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  36%|███▋      | 33/91 [00:01<00:03, 16.98it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1932/1990 [03:15<00:05,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1933/1990 [03:16<00:05,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  38%|███▊      | 35/91 [00:02<00:03, 16.63it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1934/1990 [03:16<00:05,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1935/1990 [03:16<00:05,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  41%|████      | 37/91 [00:02<00:03, 16.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1936/1990 [03:16<00:05,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1937/1990 [03:16<00:05,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  43%|████▎     | 39/91 [00:02<00:03, 16.01it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1938/1990 [03:16<00:05,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  97%|█████████▋| 1939/1990 [03:16<00:05,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  45%|████▌     | 41/91 [00:02<00:03, 13.43it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1940/1990 [03:16<00:05,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1941/1990 [03:16<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  47%|████▋     | 43/91 [00:02<00:03, 12.96it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1942/1990 [03:16<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1943/1990 [03:16<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  49%|████▉     | 45/91 [00:02<00:04, 11.19it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1944/1990 [03:16<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1945/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  52%|█████▏    | 47/91 [00:03<00:03, 11.18it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1946/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1947/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  54%|█████▍    | 49/91 [00:03<00:03, 10.72it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1948/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1949/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  56%|█████▌    | 51/91 [00:03<00:03, 10.68it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1950/1990 [03:17<00:04,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1951/1990 [03:17<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  58%|█████▊    | 53/91 [00:03<00:03, 10.55it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1952/1990 [03:17<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1953/1990 [03:17<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  60%|██████    | 55/91 [00:03<00:03, 10.78it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1954/1990 [03:17<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1955/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  63%|██████▎   | 57/91 [00:04<00:03, 10.02it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1956/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1957/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  65%|██████▍   | 59/91 [00:04<00:03, 10.17it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1958/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  98%|█████████▊| 1959/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  67%|██████▋   | 61/91 [00:04<00:03,  9.73it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1960/1990 [03:18<00:03,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  68%|██████▊   | 62/91 [00:04<00:03,  9.21it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 1961/1990 [03:18<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▊| 1962/1990 [03:18<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  70%|███████   | 64/91 [00:04<00:02,  9.54it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 1963/1990 [03:18<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▊| 1964/1990 [03:18<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  73%|███████▎  | 66/91 [00:05<00:02,  9.07it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 1965/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1966/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  75%|███████▍  | 68/91 [00:05<00:02,  9.84it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1967/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1968/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  77%|███████▋  | 70/91 [00:05<00:02,  8.74it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1969/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1970/1990 [03:19<00:02,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  79%|███████▉  | 72/91 [00:05<00:02,  9.44it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1971/1990 [03:19<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1972/1990 [03:19<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  81%|████████▏ | 74/91 [00:05<00:01,  8.57it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1973/1990 [03:20<00:01,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1974/1990 [03:20<00:01,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  84%|████████▎ | 76/91 [00:06<00:01,  9.31it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1975/1990 [03:20<00:01,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1976/1990 [03:20<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  86%|████████▌ | 78/91 [00:06<00:01,  9.36it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1977/1990 [03:20<00:01,  9.86it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1978/1990 [03:20<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  88%|████████▊ | 80/91 [00:06<00:01, 10.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1979/1990 [03:20<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0:  99%|█████████▉| 1980/1990 [03:20<00:01,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  90%|█████████ | 82/91 [00:06<00:00, 10.09it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1981/1990 [03:20<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|█████████▉| 1982/1990 [03:20<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  92%|█████████▏| 84/91 [00:06<00:00, 10.77it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1983/1990 [03:20<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|█████████▉| 1984/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  95%|█████████▍| 86/91 [00:07<00:00,  9.85it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1985/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|█████████▉| 1986/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  97%|█████████▋| 88/91 [00:07<00:00, 10.55it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1987/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|█████████▉| 1988/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Validation DataLoader 0:  99%|█████████▉| 90/91 [00:07<00:00, 10.46it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1989/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|██████████| 1990/1990 [03:21<00:00,  9.87it/s, loss=0.0226, v_num=29]日誌檢查開始\n",
      "test_labels shape: torch.Size([2912, 2])\n",
      "last_x: 500\n",
      "calibration_train_labels shape: (2412, 2)\n",
      "calibration_train shape: (2412, 2)\n",
      "Epoch 0: 100%|██████████| 1990/1990 [03:32<00:00,  9.36it/s, loss=0.0226, v_num=29]\n",
      "Epoch 0: 100%|██████████| 1990/1990 [03:32<00:00,  9.36it/s, loss=0.0226, v_num=29]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1899: 'valid/offset(k=0)/loss' reached 0.04284 (best 0.04284), saving model to './saved_models/p00\\\\p00_best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1990/1990 [03:32<00:00,  9.36it/s, loss=0.0226, v_num=29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 90/90 [00:07<00:00, 11.14it/s]日誌檢查開始\n",
      "test_labels shape: torch.Size([2880, 2])\n",
      "last_x: 500\n",
      "calibration_train_labels shape: (2380, 2)\n",
      "calibration_train shape: (2380, 2)\n",
      "Testing DataLoader 0: 100%|██████████| 90/90 [00:17<00:00,  5.10it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "                  Test metric                                   DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "epoch_end_test/offset(k=128)/mean_angular_error              11.068146989822388\n",
      "epoch_end_test/offset(k=128)/std_angular_error              0.012213014576228998\n",
      " epoch_end_test/offset(k=9)/mean_angular_error               11.123067573547363\n",
      " epoch_end_test/offset(k=9)/std_angular_error                0.07988418199430629\n",
      "  epoch_end_test/offset(k=all)/angular_error                 11.072676658630371\n",
      "        test/offset(k=0)/angular_error                        16.23507308959961\n",
      "             test/offset(k=0)/loss                           0.04563921317458153\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "path_to_data = './data/mpiifacegaze_preprocessed'\n",
    "validate_on_person = 0\n",
    "test_on_person = 1\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0\n",
    "batch_size = 32\n",
    "k = [9, 128]\n",
    "adjust_slope = False\n",
    "grid_calibration_samples = True\n",
    "\n",
    "main(path_to_data, validate_on_person, test_on_person, learning_rate, weight_decay, batch_size, k, adjust_slope, grid_calibration_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9845b-9d66-4d3e-9abc-812241e34b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743430ab-8683-4733-90e7-15f44798f1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a858d-62f4-4472-a205-d57f89612673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
