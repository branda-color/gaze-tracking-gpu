{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "370f3c67-da3e-489d-8a54-882f2aed8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load eval.py\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "\n",
    "from dataset.mpii_face_gaze_dataset import get_dataloaders\n",
    "from train import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import calc_angle_error,compute_bias_eq3\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d364906e-0439-4ce4-bbaf-becbf9197e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_eq3(model, test_set, device='cuda', s=9, target_pitch=0.0, target_yaw=0.0):\n",
    "    \"\"\"\n",
    "    用 Eq.3 進行校正後測試，模擬 SGTC (Single Gaze Target Calibration)\n",
    "\n",
    "    :param model: 已訓練好的模型\n",
    "    :param test_set: 測試資料 (list of dict)\n",
    "    :param device: 'cuda' or 'cpu'\n",
    "    :param s: 校正用圖數量 S\n",
    "    :param target_pitch: 要選的注視點 pitch 值\n",
    "    :param target_yaw: 要選的注視點 yaw 值\n",
    "    :return: 平均 angular error\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: 從 test_set 選擇 S 張符合 gaze target 條件的樣本當作 calibration set\n",
    "    calibration_samples = [\n",
    "        item for item in test_set\n",
    "        if abs(item['gaze_pitch'] - target_pitch) < 0.1 and abs(item['gaze_yaw'] - target_yaw) < 0.1\n",
    "    ][:s]\n",
    "\n",
    "    if len(calibration_samples) < s:\n",
    "        print(f\"⚠️ 校正圖數不足 {s} 張，只找到 {len(calibration_samples)} 張\")\n",
    "        return None\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    calibration_filenames = set(item['file_name'] for item in calibration_samples)\n",
    "    \n",
    "    # Step 2: 計算 Eq.3 偏移 b̂\n",
    "    b_hat = compute_bias_eq3(model, calibration_samples, device)\n",
    "\n",
    "    # Step 3: 用 b̂ 預測其他 test 圖\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in test_set:\n",
    "            # 如果是 calibration sample 就跳過，避免重複\n",
    "            if item['file_name'] in calibration_filenames:\n",
    "                continue\n",
    "\n",
    "            full_face = item['full_face_image'].unsqueeze(0).to(device)\n",
    "            right_eye = item['right_eye_image'].unsqueeze(0).to(device)\n",
    "            left_eye = item['left_eye_image'].unsqueeze(0).to(device)\n",
    "\n",
    "            t_hat = model.get_subject_independent_output(full_face, right_eye, left_eye)\n",
    "            g_hat = t_hat + b_hat.to(t_hat.device)\n",
    "            #print(\"t_hat device:\", t_hat.device)\n",
    "            #print(\"b_hat device:\", b_hat.device)\n",
    "            #print(\"model bias device:\", model.subject_biases.device)\n",
    "            #print(\"g_hat device:\", g_hat.device)\n",
    "\n",
    "            preds.append(g_hat.squeeze(0).cpu())\n",
    "            labels.append(torch.tensor([\n",
    "                float(item['gaze_pitch']),\n",
    "                float(item['gaze_yaw'])\n",
    "            ], device=device, dtype=torch.float32))\n",
    "\n",
    "    preds = torch.stack(preds)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    # Step 4: 計算 angular error\n",
    "    mean_angle_error = calc_angle_error(labels.cpu(), preds.cpu()).item()\n",
    "    print(f'🎯 Mean angular error after Eq.3 calibration(S={s}): {mean_angle_error:.2f}°')\n",
    "    return mean_angle_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71a5cdd1-dcdd-4f29-8aa2-3286679ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration_lr(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    使用 Linear Regression 做視線偏移校正\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # 選 S 張圖作為校正資料\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # 擷取 calibration 資料的 pred & label\n",
    "        preds, labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            label = d['label'].cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "        # 執行 Linear Regression 擬合 (pred -> label)\n",
    "        reg = LinearRegression().fit(preds, labels)\n",
    "\n",
    "        # 測試時套用 regression 校正\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            corrected = reg.predict([pred])[0]\n",
    "            angle = calc_angle_error(\n",
    "                torch.tensor(corrected).unsqueeze(0).to(device),\n",
    "                d['label'].unsqueeze(0)\n",
    "            )\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"📐 Linear Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c540133-8e27-4300-8cb9-af07f3a48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    模擬 S 張圖當校正資料，對剩下資料測試。\n",
    "    模型 forward 接收格式：FinalModel(person_idx, full_face, right_eye, left_eye)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)  # shape [1, 1]\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # Step 1：選 S 張圖當校正資料\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Step 2：計算 bias\n",
    "        cal_outputs, cal_labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0)\n",
    "            cal_outputs.append(pred)\n",
    "            cal_labels.append(d['label'])\n",
    "\n",
    "        bias = torch.stack(cal_labels).mean(dim=0) - torch.stack(cal_outputs).mean(dim=0)\n",
    "\n",
    "        # Step 3：套用 bias 做測試\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0) + bias\n",
    "\n",
    "            angle = calc_angle_error(pred.unsqueeze(0), d['label'].unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"📐 Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a87f414e-5956-4245-9688-cf91f9bf2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models/p00/p00_best-v28.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\gazegpu\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on persons [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "valid on person 0\n",
      "test on person 1\n",
      "len(dataset_train) 60784\n",
      "len(dataset_valid) 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset_test) 2904\n",
      "Testing DataLoader 0: 100%|██████████| 181/181 [00:26<00:00,  6.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "             Test metric                         DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test/offset(k=0)/angular_error             3.6843433380126953\n",
      "        test/offset(k=0)/loss                0.002673023846000433\n",
      "test/offset(k=128)/mean_angular_error         2.7848633340120315\n",
      "test/offset(k=128)/std_angular_error         0.029947001860490575\n",
      " test/offset(k=9)/mean_angular_error           2.940035085964203\n",
      " test/offset(k=9)/std_angular_error           0.18966737049682192\n",
      "  test/offset(k=all)/angular_error             2.773134469985962\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "🎯 Mean angular error after Eq.3 calibration(S=1): 3.59°\n",
      "🎯 Mean angular error after Eq.3 calibration(S=5): 3.61°\n",
      "🎯 Mean angular error after Eq.3 calibration(S=9): 3.70°\n",
      "🎯 Mean angular error after Eq.3 calibration(S=16): 3.53°\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ###非變動區塊\n",
    "    k = [9,128]\n",
    "    adjust_slope = False\n",
    "    ###對應作者表格grid calibration,如果是random就填true\n",
    "    grid_calibration_samples=False\n",
    "    batch_size =32\n",
    "    path_to_data = './data/mpiifacegaze_preprocessed'\n",
    "    \n",
    "    \n",
    "    ####變動區塊\n",
    "    path_to_checkpoints = './saved_models/p00/p00_best-v28.ckpt'\n",
    "    person_idx = 1\n",
    "    validate_on_person = 0 \n",
    "    \n",
    "    seed_everything(42)\n",
    "\n",
    "    print(f\"{path_to_checkpoints}\")\n",
    "    \n",
    "    model = Model.load_from_checkpoint(path_to_checkpoints, k=[9, 128], adjust_slope=False, grid_calibration_samples=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        gpus=1,\n",
    "        benchmark=True,\n",
    "    )\n",
    "\n",
    "    _, _, test_dataloader = get_dataloaders(\n",
    "        path_to_data, \n",
    "        validate_on_person, \n",
    "        person_idx, \n",
    "        batch_size   \n",
    "    )\n",
    "     \n",
    "    trainer.test(model, test_dataloader)\n",
    "\n",
    "    ####################拿出 test set（單人完整資料）\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    #######################\n",
    "\n",
    "    evaluate_with_eq3(model, test_dataset, s=1, target_pitch=0.0, target_yaw=0.0)\n",
    "    evaluate_with_eq3(model, test_dataset, s=5, target_pitch=0.0, target_yaw=0.0)\n",
    "    evaluate_with_eq3(model, test_dataset, s=9, target_pitch=0.0, target_yaw=0.0)\n",
    "    evaluate_with_eq3(model, test_dataset, s=16, target_pitch=0.0, target_yaw=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e892-4c57-4eb5-b293-065775805be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
