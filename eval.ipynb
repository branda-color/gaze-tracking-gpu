{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e36f109-973f-472f-be53-5d67c3a96413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370f3c67-da3e-489d-8a54-882f2aed8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.7 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "# %load eval.py\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "\n",
    "from dataset.mpii_face_gaze_dataset import get_dataloaders\n",
    "from train import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import calc_angle_error,compute_bias_eq3,calc_angle_error_for_eval\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58d3276-5332-42d3-a4ea-b16cec0d2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_MGTC_calibration_samples(test_set, s=9, grid_bins=4):\n",
    "    \"\"\"\n",
    "    ÂæûÊï¥ÂÄãÊ∏¨Ë©¶ÈõÜ‰∏≠ÈÅ∏Êìá‰æÜËá™‰∏çÂêå gaze ÊñπÂêëÁöÑ S ÂºµÊ®£Êú¨ÔºåÁî®Êñº MGTC Ê®°Êì¨„ÄÇ\n",
    "    \n",
    "    :param test_set: Ê∏¨Ë©¶Ë≥áÊñôÈõÜÔºàlist of dictÔºâ\n",
    "    :param s: ÈúÄË¶ÅÊäΩÂèñÁöÑÊ®£Êú¨Êï∏\n",
    "    :param grid_bins: pitch/yaw Á©∫ÈñìÂàÜÂâ≤Ê†ºÊï∏ÔºàÈ†êË®≠ 8x8Ôºâ\n",
    "    :return: List of dictÔºàË¢´ÈÅ∏Âá∫ÁöÑ sampleÔºâ\n",
    "    \"\"\"\n",
    "\n",
    "    # ÊØèÂÄã sample ÁöÑ pitch/yaw ËΩâÊàêÊ†ºÂ≠ê key\n",
    "    bins = {}\n",
    "    for idx, item in enumerate(test_set):\n",
    "        pitch = float(item['gaze_pitch'])\n",
    "        yaw = float(item['gaze_yaw'])\n",
    "\n",
    "        pitch_bin = int((pitch + np.pi / 2) / (np.pi / grid_bins))\n",
    "        yaw_bin = int((yaw + np.pi / 2) / (np.pi / grid_bins))\n",
    "        key = (pitch_bin, yaw_bin)\n",
    "\n",
    "        if key not in bins:\n",
    "            bins[key] = []\n",
    "        bins[key].append(item)\n",
    "\n",
    "    # Èö®Ê©üÂæû‰∏çÂêåÊ†ºÂ≠êÊäΩÊ®£ÔºåÁõ°ÈáèÊåëÂá∫ s ÂºµÂúñ\n",
    "    keys = list(bins.keys())\n",
    "    random.shuffle(keys)\n",
    "\n",
    "    selected_samples = []\n",
    "    for key in keys:\n",
    "        candidates = bins[key]\n",
    "        if candidates:\n",
    "            chosen = random.choice(candidates)\n",
    "            selected_samples.append(chosen)\n",
    "        if len(selected_samples) >= s:\n",
    "            break\n",
    "\n",
    "    if len(selected_samples) < s:\n",
    "        print(f\"‚ö†Ô∏è MGTC ÊäΩÊ®£Â§±ÊïóÔºåÂè™ÂèñÂæó {len(selected_samples)} ÂºµÊ®£Êú¨\")\n",
    "\n",
    "    return selected_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e2c7c4-07ae-41c7-927c-c8199f9836a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_eq3_repeat(model, test_set, s=9, repeat_times=10, target_pitch=0.0, target_yaw=0.0, device='cuda', use_mgtc=False):\n",
    "    \"\"\"\n",
    "    ÈáçË§áÂ§öÊ¨°Èö®Ê©üÊåëÈÅ∏ S ÂºµÊ†°Ê≠£ÂúñÔºåÊ®°Êì¨‰ΩúËÄÖË´ñÊñá‰∏≠ÁöÑ ¬± Ë™§Â∑ÆÁµ±Ë®à\n",
    "\n",
    "    :param model: Â∑≤Ë®ìÁ∑¥Â•ΩÁöÑÊ®°Âûã\n",
    "    :param test_set: Ê∏¨Ë©¶Ë≥áÊñôÈõÜÔºàlist of dictÔºâ\n",
    "    :param s: ÊØèÊ¨°Ê†°Ê≠£ÂúñÊï∏Èáè S\n",
    "    :param repeat_times: ÈáçË§áÂπæÊ¨°Ê†°Ê≠£Ë©¶È©ó\n",
    "    :param target_pitch: Ê†°Ê≠£Ê≥®Ë¶ñÈªû pitchÔºàÈ†êË®≠ 0.0Ôºâ\n",
    "    :param target_yaw: Ê†°Ê≠£Ê≥®Ë¶ñÈªû yawÔºàÈ†êË®≠ 0.0Ôºâ\n",
    "    :param device: È†êË®≠ 'cuda'\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(f\"üîç Ê†°Ê≠£Ê®°ÂºèÔºö{'MGTCÔºàÂ§öÊñπÂêëÔºâ' if use_mgtc else 'SGTCÔºàÂñÆÊñπÂêëÔºâ'}\")\n",
    "\n",
    "    all_mean_errors = []\n",
    "\n",
    "    for trial in range(repeat_times):\n",
    "        # Step 1: ÊâæÂá∫Á¨¶ÂêàÁõÆÊ®ôÊ≥®Ë¶ñÈªûÁöÑÊ®£Êú¨(STGC/MTGC)\n",
    "\n",
    "        if use_mgtc:\n",
    "            calibration_samples = select_MGTC_calibration_samples(test_set, s=s)\n",
    "            if len(calibration_samples) < s:\n",
    "                print(f\"‚ö†Ô∏è Á¨¨ {trial+1} Ê¨° MGTC ÂÉÖÂèñÂæó {len(calibration_samples)} ÂºµÔºåÂ∞áÈö®Ê©üË£úÊªø\")\n",
    "                # ÈÄôË£°ÊØîÂ∞ç file_name ÈÅøÂÖç tensor ÁÑ°Ê≥ïÊØîËºÉÁöÑÈåØË™§\n",
    "                calibration_names = set(item['file_name'] for item in calibration_samples)\n",
    "                remaining = [item for item in test_set if item['file_name'] not in calibration_names]\n",
    "                extra = random.sample(remaining, s - len(calibration_samples))\n",
    "                calibration_samples += extra\n",
    "        else:\n",
    "            calibration_samples = [\n",
    "                item for item in test_set\n",
    "                if abs(item['gaze_pitch'] - target_pitch) < 0.1 and abs(item['gaze_yaw'] - target_yaw) < 0.1\n",
    "            ]\n",
    "            if len(calibration_samples) < s:\n",
    "                print(f\"‚ùå Á¨¨ {trial+1} Ê¨°Ê†°Ê≠£Â§±ÊïóÔºåÁ¨¶ÂêàÊ¢ù‰ª∂ÁöÑÂúñÂÉè‰∏çË∂≥ {s} Âºµ\")\n",
    "                continue\n",
    "\n",
    "        selected = random.sample(calibration_samples, s)\n",
    "        cal_names = set(item['file_name'] for item in selected)\n",
    "\n",
    "        # Step 2: Ë®àÁÆóÂÅèÁßªÈáè\n",
    "        b_hat = compute_bias_eq3(model, selected, device)\n",
    "\n",
    "        # Step 3: Ê∏¨Ë©¶ÂÖ∂È§òÂúñÁâáÁöÑ angular error\n",
    "        preds, labels = [], []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for item in test_set:\n",
    "                if item['file_name'] in cal_names:\n",
    "                    continue\n",
    "\n",
    "                full_face = item['full_face_image'].unsqueeze(0).to(device)\n",
    "                right_eye = item['right_eye_image'].unsqueeze(0).to(device)\n",
    "                left_eye = item['left_eye_image'].unsqueeze(0).to(device)\n",
    "\n",
    "                t_hat = model.get_subject_independent_output(full_face, right_eye, left_eye)\n",
    "                g_hat = t_hat + b_hat.to(t_hat.device)\n",
    "\n",
    "                preds.append(g_hat.squeeze(0).cpu())\n",
    "                labels.append(torch.tensor([\n",
    "                    float(item['gaze_pitch']),\n",
    "                    float(item['gaze_yaw'])\n",
    "                ], dtype=torch.float32))\n",
    "\n",
    "        # Step 4: Ë®àÁÆó‰∏ÄÊ¨° mean angular error\n",
    "        preds = torch.stack(preds)\n",
    "        labels = torch.stack(labels)\n",
    "        error = calc_angle_error_for_eval(labels, preds).mean().item()\n",
    "        all_mean_errors.append(error)\n",
    "\n",
    "    # Step 5: ÊúÄÁµÇ ¬± Áµ±Ë®à\n",
    "    if len(all_mean_errors) == 0:\n",
    "        print(\"‚ö†Ô∏è ÊâÄÊúâË©¶È©óÈÉΩÂ§±ÊïóÔºåÁÑ°Ê≥ïÁî¢Áîü ¬± Áµ±Ë®à\")\n",
    "        return None\n",
    "\n",
    "    mean_err = np.mean(all_mean_errors)\n",
    "    std_err = np.std(all_mean_errors)\n",
    "    print(f\"üìê Angular Error (S={s}, N={repeat_times}): {mean_err:.2f} ¬± {std_err:.2f} degrees\")\n",
    "\n",
    "    return mean_err, std_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d364906e-0439-4ce4-bbaf-becbf9197e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Êñ∞Â¢ûÈÄôÂÄãËºîÂä©ÂáΩÊï∏\n",
    "def calculate_error_distribution(error_list):\n",
    "    \"\"\"\n",
    "    Ëº∏ÂÖ•ÊØèÂºµÂúñÁöÑ angular error listÔºåËº∏Âá∫ mean ¬± std ‰∏¶Âç∞Âá∫\n",
    "    \"\"\"\n",
    "    mean_angle = np.mean(error_list)\n",
    "    std_angle = np.std(error_list)\n",
    "    print(f\"üìê Angular Error: {mean_angle:.2f} ¬± {std_angle:.2f} degrees\")\n",
    "    return mean_angle, std_angle\n",
    "# ‚úÖ ‰∏ªÂáΩÊï∏\n",
    "def evaluate_with_eq3(model, test_set, device='cuda', s=9, target_pitch=0.0, target_yaw=0.0):\n",
    "    \"\"\"\n",
    "    Áî® Eq.3 ÈÄ≤Ë°åÊ†°Ê≠£ÂæåÊ∏¨Ë©¶ÔºåÊ®°Êì¨ SGTC (Single Gaze Target Calibration)\n",
    "    \"\"\"\n",
    "    # Step 1: ÈÅ∏ÊìáÊ†°Ê≠£ÂúñÂÉè\n",
    "    calibration_samples = [\n",
    "        item for item in test_set\n",
    "        if abs(item['gaze_pitch'] - target_pitch) < 0.1 and abs(item['gaze_yaw'] - target_yaw) < 0.1\n",
    "    ][:s]\n",
    "\n",
    "    if len(calibration_samples) < s:\n",
    "        print(f\"‚ö†Ô∏è Ê†°Ê≠£ÂúñÊï∏‰∏çË∂≥ {s} ÂºµÔºåÂè™ÊâæÂà∞ {len(calibration_samples)} Âºµ\")\n",
    "        return None\n",
    "\n",
    "    model = model.to(device)\n",
    "    calibration_filenames = set(item['file_name'] for item in calibration_samples)\n",
    "\n",
    "    # Step 2: Ë®àÁÆó Eq.3 ÂÅèÁßª bÃÇ\n",
    "    b_hat = compute_bias_eq3(model, calibration_samples, device)\n",
    "\n",
    "    # Step 3: ‰ΩøÁî®ÂÅèÁßªÈÄ≤Ë°åÈ†êÊ∏¨\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    ### ‚úÖ ‰øÆÊîπÈªû STARTÔºöË®òÈåÑÊØèÂºµ angular error\n",
    "    angle_errors = []\n",
    "    ### ‚úÖ ‰øÆÊîπÈªû END\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in test_set:\n",
    "            if item['file_name'] in calibration_filenames:\n",
    "                continue\n",
    "\n",
    "            full_face = item['full_face_image'].unsqueeze(0).to(device)\n",
    "            right_eye = item['right_eye_image'].unsqueeze(0).to(device)\n",
    "            left_eye = item['left_eye_image'].unsqueeze(0).to(device)\n",
    "\n",
    "            t_hat = model.get_subject_independent_output(full_face, right_eye, left_eye)\n",
    "            g_hat = t_hat + b_hat.to(t_hat.device)\n",
    "\n",
    "            preds.append(g_hat.squeeze(0).cpu())\n",
    "            label_tensor = torch.tensor([\n",
    "                float(item['gaze_pitch']),\n",
    "                float(item['gaze_yaw'])\n",
    "            ], device=device, dtype=torch.float32)\n",
    "            labels.append(label_tensor)\n",
    "\n",
    "            ### ‚úÖ ‰øÆÊîπÈªû STARTÔºöÂñÆÂºµ angular error Ë®òÈåÑ\n",
    "            angle = calc_angle_error(label_tensor.unsqueeze(0), g_hat.squeeze(0).unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "            ### ‚úÖ ‰øÆÊîπÈªû END\n",
    "\n",
    "    # Step 4: Ëº∏Âá∫ ¬± Áµ±Ë®à\n",
    "    calculate_error_distribution(angle_errors)\n",
    "\n",
    "    return np.mean(angle_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a5cdd1-dcdd-4f29-8aa2-3286679ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration_lr(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    ‰ΩøÁî® Linear Regression ÂÅöË¶ñÁ∑öÂÅèÁßªÊ†°Ê≠£\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # ÈÅ∏ S ÂºµÂúñ‰ΩúÁÇ∫Ê†°Ê≠£Ë≥áÊñô\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Êì∑Âèñ calibration Ë≥áÊñôÁöÑ pred & label\n",
    "        preds, labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            label = d['label'].cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "        # Âü∑Ë°å Linear Regression Êì¨Âêà (pred -> label)\n",
    "        reg = LinearRegression().fit(preds, labels)\n",
    "\n",
    "        # Ê∏¨Ë©¶ÊôÇÂ•óÁî® regression Ê†°Ê≠£\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            corrected = reg.predict([pred])[0]\n",
    "            angle = calc_angle_error(\n",
    "                torch.tensor(corrected).unsqueeze(0).to(device),\n",
    "                d['label'].unsqueeze(0)\n",
    "            )\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"üìê Linear Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c540133-8e27-4300-8cb9-af07f3a48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    Ê®°Êì¨ S ÂºµÂúñÁï∂Ê†°Ê≠£Ë≥áÊñôÔºåÂ∞çÂâ©‰∏ãË≥áÊñôÊ∏¨Ë©¶„ÄÇ\n",
    "    Ê®°Âûã forward Êé•Êî∂Ê†ºÂºèÔºöFinalModel(person_idx, full_face, right_eye, left_eye)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)  # shape [1, 1]\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # Step 1ÔºöÈÅ∏ S ÂºµÂúñÁï∂Ê†°Ê≠£Ë≥áÊñô\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Step 2ÔºöË®àÁÆó bias\n",
    "        cal_outputs, cal_labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0)\n",
    "            cal_outputs.append(pred)\n",
    "            cal_labels.append(d['label'])\n",
    "\n",
    "        bias = torch.stack(cal_labels).mean(dim=0) - torch.stack(cal_outputs).mean(dim=0)\n",
    "\n",
    "        # Step 3ÔºöÂ•óÁî® bias ÂÅöÊ∏¨Ë©¶\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0) + bias\n",
    "\n",
    "            angle = calc_angle_error(pred.unsqueeze(0), d['label'].unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"üìê Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87f414e-5956-4245-9688-cf91f9bf2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models/p00/p00_best-v46.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\gazegpu\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on persons [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "valid on person 0\n",
      "test on person 1\n",
      "len(dataset_train) 60784\n",
      "len(dataset_valid) 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset_test) 2904\n",
      "Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181/181 [00:26<00:00,  6.78it/s]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "             Test metric                         DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   test/offset(k=0)/angular_error              3.207423686981201\n",
      "        test/offset(k=0)/loss                0.0019713188521564007\n",
      "test/offset(k=128)/mean_angular_error         2.4511219635009764\n",
      "test/offset(k=128)/std_angular_error         0.016094765126522557\n",
      " test/offset(k=9)/mean_angular_error           2.528395970821381\n",
      " test/offset(k=9)/std_angular_error           0.11120549839860427\n",
      "  test/offset(k=all)/angular_error             2.450024366378784\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ###ÈùûËÆäÂãïÂçÄÂ°ä\n",
    "    k = [9,128]\n",
    "    adjust_slope = False\n",
    "    ###Â∞çÊáâ‰ΩúËÄÖË°®Ê†ºgrid calibration,Â¶ÇÊûúÊòØrandomÂ∞±Â°´true\n",
    "    grid_calibration_samples=True\n",
    "    batch_size =32\n",
    "    path_to_data = './data/mpiifacegaze_preprocessed'\n",
    "    \n",
    "    \n",
    "    ####ËÆäÂãïÂçÄÂ°ä\n",
    "    path_to_checkpoints = './saved_models/p00/p00_best-v46.ckpt'\n",
    "    person_idx = 1\n",
    "    validate_on_person = 0 \n",
    "    \n",
    "    seed_everything(42)\n",
    "\n",
    "    print(f\"{path_to_checkpoints}\")\n",
    "    \n",
    "    model = Model.load_from_checkpoint(path_to_checkpoints, k=[9, 128], adjust_slope=False, grid_calibration_samples=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        gpus=1,\n",
    "        benchmark=True,\n",
    "    )\n",
    "\n",
    "    _, _, test_dataloader = get_dataloaders(\n",
    "        path_to_data, \n",
    "        validate_on_person, \n",
    "        person_idx, \n",
    "        batch_size   \n",
    "    )\n",
    "     \n",
    "    trainer.test(model, test_dataloader)\n",
    "\n",
    "    ####################ÊãøÂá∫ test setÔºàÂñÆ‰∫∫ÂÆåÊï¥Ë≥áÊñôÔºâ\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    #######################\n",
    "\n",
    "\n",
    "    #####STGCÂëºÂè´##########\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=1, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=5, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=9, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=16, repeat_times=10)\n",
    "\n",
    "    ######MTGC\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=1, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=5, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=9, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=16, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=32, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=64, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=128, repeat_times=10, use_mgtc=True)\n",
    "\n",
    "\n",
    "\n",
    "    #evaluate_with_eq3(model, test_dataset, s=1, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=5, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=9, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=16, target_pitch=0.0, target_yaw=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e892-4c57-4eb5-b293-065775805be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
