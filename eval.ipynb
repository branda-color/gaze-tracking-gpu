{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e36f109-973f-472f-be53-5d67c3a96413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370f3c67-da3e-489d-8a54-882f2aed8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.7 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "# %load eval.py\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "\n",
    "from dataset.mpii_face_gaze_dataset import get_dataloaders\n",
    "from train import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import calc_angle_error,compute_bias_eq3,calc_angle_error_for_eval\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58d3276-5332-42d3-a4ea-b16cec0d2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_MGTC_calibration_samples(test_set, s=9, grid_bins=4):\n",
    "    \"\"\"\n",
    "    從整個測試集中選擇來自不同 gaze 方向的 S 張樣本，用於 MGTC 模擬。\n",
    "    \n",
    "    :param test_set: 測試資料集（list of dict）\n",
    "    :param s: 需要抽取的樣本數\n",
    "    :param grid_bins: pitch/yaw 空間分割格數（預設 8x8）\n",
    "    :return: List of dict（被選出的 sample）\n",
    "    \"\"\"\n",
    "\n",
    "    # 每個 sample 的 pitch/yaw 轉成格子 key\n",
    "    bins = {}\n",
    "    for idx, item in enumerate(test_set):\n",
    "        pitch = float(item['gaze_pitch'])\n",
    "        yaw = float(item['gaze_yaw'])\n",
    "\n",
    "        pitch_bin = int((pitch + np.pi / 2) / (np.pi / grid_bins))\n",
    "        yaw_bin = int((yaw + np.pi / 2) / (np.pi / grid_bins))\n",
    "        key = (pitch_bin, yaw_bin)\n",
    "\n",
    "        if key not in bins:\n",
    "            bins[key] = []\n",
    "        bins[key].append(item)\n",
    "\n",
    "    # 隨機從不同格子抽樣，盡量挑出 s 張圖\n",
    "    keys = list(bins.keys())\n",
    "    random.shuffle(keys)\n",
    "\n",
    "    selected_samples = []\n",
    "    for key in keys:\n",
    "        candidates = bins[key]\n",
    "        if candidates:\n",
    "            chosen = random.choice(candidates)\n",
    "            selected_samples.append(chosen)\n",
    "        if len(selected_samples) >= s:\n",
    "            break\n",
    "\n",
    "    if len(selected_samples) < s:\n",
    "        print(f\"⚠️ MGTC 抽樣失敗，只取得 {len(selected_samples)} 張樣本\")\n",
    "\n",
    "    return selected_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e2c7c4-07ae-41c7-927c-c8199f9836a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_eq3_repeat(model, test_set, s=9, repeat_times=10, target_pitch=0.0, target_yaw=0.0, device='cuda', use_mgtc=False):\n",
    "    \"\"\"\n",
    "    重複多次隨機挑選 S 張校正圖，模擬作者論文中的 ± 誤差統計\n",
    "\n",
    "    :param model: 已訓練好的模型\n",
    "    :param test_set: 測試資料集（list of dict）\n",
    "    :param s: 每次校正圖數量 S\n",
    "    :param repeat_times: 重複幾次校正試驗\n",
    "    :param target_pitch: 校正注視點 pitch（預設 0.0）\n",
    "    :param target_yaw: 校正注視點 yaw（預設 0.0）\n",
    "    :param device: 預設 'cuda'\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(f\"🔍 校正模式：{'MGTC（多方向）' if use_mgtc else 'SGTC（單方向）'}\")\n",
    "\n",
    "    all_mean_errors = []\n",
    "\n",
    "    for trial in range(repeat_times):\n",
    "        # Step 1: 找出符合目標注視點的樣本(STGC/MTGC)\n",
    "\n",
    "        if use_mgtc:\n",
    "            calibration_samples = select_MGTC_calibration_samples(test_set, s=s)\n",
    "            if len(calibration_samples) < s:\n",
    "                print(f\"⚠️ 第 {trial+1} 次 MGTC 僅取得 {len(calibration_samples)} 張，將隨機補滿\")\n",
    "                # 這裡比對 file_name 避免 tensor 無法比較的錯誤\n",
    "                calibration_names = set(item['file_name'] for item in calibration_samples)\n",
    "                remaining = [item for item in test_set if item['file_name'] not in calibration_names]\n",
    "                extra = random.sample(remaining, s - len(calibration_samples))\n",
    "                calibration_samples += extra\n",
    "        else:\n",
    "            calibration_samples = [\n",
    "                item for item in test_set\n",
    "                if abs(item['gaze_pitch'] - target_pitch) < 0.1 and abs(item['gaze_yaw'] - target_yaw) < 0.1\n",
    "            ]\n",
    "            if len(calibration_samples) < s:\n",
    "                print(f\"❌ 第 {trial+1} 次校正失敗，符合條件的圖像不足 {s} 張\")\n",
    "                continue\n",
    "\n",
    "        selected = random.sample(calibration_samples, s)\n",
    "        cal_names = set(item['file_name'] for item in selected)\n",
    "\n",
    "        # Step 2: 計算偏移量\n",
    "        b_hat = compute_bias_eq3(model, selected, device)\n",
    "\n",
    "        # Step 3: 測試其餘圖片的 angular error\n",
    "        preds, labels = [], []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for item in test_set:\n",
    "                if item['file_name'] in cal_names:\n",
    "                    continue\n",
    "\n",
    "                full_face = item['full_face_image'].unsqueeze(0).to(device)\n",
    "                right_eye = item['right_eye_image'].unsqueeze(0).to(device)\n",
    "                left_eye = item['left_eye_image'].unsqueeze(0).to(device)\n",
    "\n",
    "                t_hat = model.get_subject_independent_output(full_face, right_eye, left_eye)\n",
    "                g_hat = t_hat + b_hat.to(t_hat.device)\n",
    "\n",
    "                preds.append(g_hat.squeeze(0).cpu())\n",
    "                labels.append(torch.tensor([\n",
    "                    float(item['gaze_pitch']),\n",
    "                    float(item['gaze_yaw'])\n",
    "                ], dtype=torch.float32))\n",
    "\n",
    "        # Step 4: 計算一次 mean angular error\n",
    "        preds = torch.stack(preds)\n",
    "        labels = torch.stack(labels)\n",
    "        error = calc_angle_error_for_eval(labels, preds).mean().item()\n",
    "        all_mean_errors.append(error)\n",
    "\n",
    "    # Step 5: 最終 ± 統計\n",
    "    if len(all_mean_errors) == 0:\n",
    "        print(\"⚠️ 所有試驗都失敗，無法產生 ± 統計\")\n",
    "        return None\n",
    "\n",
    "    mean_err = np.mean(all_mean_errors)\n",
    "    std_err = np.std(all_mean_errors)\n",
    "    print(f\"📐 Angular Error (S={s}, N={repeat_times}): {mean_err:.2f} ± {std_err:.2f} degrees\")\n",
    "\n",
    "    return mean_err, std_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d364906e-0439-4ce4-bbaf-becbf9197e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 新增這個輔助函數\n",
    "def calculate_error_distribution(error_list):\n",
    "    \"\"\"\n",
    "    輸入每張圖的 angular error list，輸出 mean ± std 並印出\n",
    "    \"\"\"\n",
    "    mean_angle = np.mean(error_list)\n",
    "    std_angle = np.std(error_list)\n",
    "    print(f\"📐 Angular Error: {mean_angle:.2f} ± {std_angle:.2f} degrees\")\n",
    "    return mean_angle, std_angle\n",
    "# ✅ 主函數\n",
    "def evaluate_with_eq3(model, test_set, device='cuda', s=9, target_pitch=0.0, target_yaw=0.0):\n",
    "    \"\"\"\n",
    "    用 Eq.3 進行校正後測試，模擬 SGTC (Single Gaze Target Calibration)\n",
    "    \"\"\"\n",
    "    # Step 1: 選擇校正圖像\n",
    "    calibration_samples = [\n",
    "        item for item in test_set\n",
    "        if abs(item['gaze_pitch'] - target_pitch) < 0.1 and abs(item['gaze_yaw'] - target_yaw) < 0.1\n",
    "    ][:s]\n",
    "\n",
    "    if len(calibration_samples) < s:\n",
    "        print(f\"⚠️ 校正圖數不足 {s} 張，只找到 {len(calibration_samples)} 張\")\n",
    "        return None\n",
    "\n",
    "    model = model.to(device)\n",
    "    calibration_filenames = set(item['file_name'] for item in calibration_samples)\n",
    "\n",
    "    # Step 2: 計算 Eq.3 偏移 b̂\n",
    "    b_hat = compute_bias_eq3(model, calibration_samples, device)\n",
    "\n",
    "    # Step 3: 使用偏移進行預測\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    ### ✅ 修改點 START：記錄每張 angular error\n",
    "    angle_errors = []\n",
    "    ### ✅ 修改點 END\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in test_set:\n",
    "            if item['file_name'] in calibration_filenames:\n",
    "                continue\n",
    "\n",
    "            full_face = item['full_face_image'].unsqueeze(0).to(device)\n",
    "            right_eye = item['right_eye_image'].unsqueeze(0).to(device)\n",
    "            left_eye = item['left_eye_image'].unsqueeze(0).to(device)\n",
    "\n",
    "            t_hat = model.get_subject_independent_output(full_face, right_eye, left_eye)\n",
    "            g_hat = t_hat + b_hat.to(t_hat.device)\n",
    "\n",
    "            preds.append(g_hat.squeeze(0).cpu())\n",
    "            label_tensor = torch.tensor([\n",
    "                float(item['gaze_pitch']),\n",
    "                float(item['gaze_yaw'])\n",
    "            ], device=device, dtype=torch.float32)\n",
    "            labels.append(label_tensor)\n",
    "\n",
    "            ### ✅ 修改點 START：單張 angular error 記錄\n",
    "            angle = calc_angle_error(label_tensor.unsqueeze(0), g_hat.squeeze(0).unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "            ### ✅ 修改點 END\n",
    "\n",
    "    # Step 4: 輸出 ± 統計\n",
    "    calculate_error_distribution(angle_errors)\n",
    "\n",
    "    return np.mean(angle_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a5cdd1-dcdd-4f29-8aa2-3286679ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration_lr(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    使用 Linear Regression 做視線偏移校正\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # 選 S 張圖作為校正資料\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # 擷取 calibration 資料的 pred & label\n",
    "        preds, labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            label = d['label'].cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "        # 執行 Linear Regression 擬合 (pred -> label)\n",
    "        reg = LinearRegression().fit(preds, labels)\n",
    "\n",
    "        # 測試時套用 regression 校正\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            corrected = reg.predict([pred])[0]\n",
    "            angle = calc_angle_error(\n",
    "                torch.tensor(corrected).unsqueeze(0).to(device),\n",
    "                d['label'].unsqueeze(0)\n",
    "            )\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"📐 Linear Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c540133-8e27-4300-8cb9-af07f3a48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    模擬 S 張圖當校正資料，對剩下資料測試。\n",
    "    模型 forward 接收格式：FinalModel(person_idx, full_face, right_eye, left_eye)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)  # shape [1, 1]\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # Step 1：選 S 張圖當校正資料\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Step 2：計算 bias\n",
    "        cal_outputs, cal_labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0)\n",
    "            cal_outputs.append(pred)\n",
    "            cal_labels.append(d['label'])\n",
    "\n",
    "        bias = torch.stack(cal_labels).mean(dim=0) - torch.stack(cal_outputs).mean(dim=0)\n",
    "\n",
    "        # Step 3：套用 bias 做測試\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0) + bias\n",
    "\n",
    "            angle = calc_angle_error(pred.unsqueeze(0), d['label'].unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"📐 Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87f414e-5956-4245-9688-cf91f9bf2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models/p00/p00_best-v46.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\gazegpu\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on persons [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "valid on person 0\n",
      "test on person 1\n",
      "len(dataset_train) 60784\n",
      "len(dataset_valid) 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset_test) 2904\n",
      "Testing DataLoader 0: 100%|██████████| 181/181 [00:26<00:00,  6.78it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "             Test metric                         DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test/offset(k=0)/angular_error              3.207423686981201\n",
      "        test/offset(k=0)/loss                0.0019713188521564007\n",
      "test/offset(k=128)/mean_angular_error         2.4511219635009764\n",
      "test/offset(k=128)/std_angular_error         0.016094765126522557\n",
      " test/offset(k=9)/mean_angular_error           2.528395970821381\n",
      " test/offset(k=9)/std_angular_error           0.11120549839860427\n",
      "  test/offset(k=all)/angular_error             2.450024366378784\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ###非變動區塊\n",
    "    k = [9,128]\n",
    "    adjust_slope = False\n",
    "    ###對應作者表格grid calibration,如果是random就填true\n",
    "    grid_calibration_samples=True\n",
    "    batch_size =32\n",
    "    path_to_data = './data/mpiifacegaze_preprocessed'\n",
    "    \n",
    "    \n",
    "    ####變動區塊\n",
    "    path_to_checkpoints = './saved_models/p00/p00_best-v46.ckpt'\n",
    "    person_idx = 1\n",
    "    validate_on_person = 0 \n",
    "    \n",
    "    seed_everything(42)\n",
    "\n",
    "    print(f\"{path_to_checkpoints}\")\n",
    "    \n",
    "    model = Model.load_from_checkpoint(path_to_checkpoints, k=[9, 128], adjust_slope=False, grid_calibration_samples=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        gpus=1,\n",
    "        benchmark=True,\n",
    "    )\n",
    "\n",
    "    _, _, test_dataloader = get_dataloaders(\n",
    "        path_to_data, \n",
    "        validate_on_person, \n",
    "        person_idx, \n",
    "        batch_size   \n",
    "    )\n",
    "     \n",
    "    trainer.test(model, test_dataloader)\n",
    "\n",
    "    ####################拿出 test set（單人完整資料）\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    #######################\n",
    "\n",
    "\n",
    "    #####STGC呼叫##########\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=1, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=5, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=9, repeat_times=10)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=16, repeat_times=10)\n",
    "\n",
    "    ######MTGC\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=1, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=5, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=9, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=16, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=32, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=64, repeat_times=10, use_mgtc=True)\n",
    "    #evaluate_with_eq3_repeat(model, test_dataset, s=128, repeat_times=10, use_mgtc=True)\n",
    "\n",
    "\n",
    "\n",
    "    #evaluate_with_eq3(model, test_dataset, s=1, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=5, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=9, target_pitch=0.0, target_yaw=0.0)\n",
    "    #evaluate_with_eq3(model, test_dataset, s=16, target_pitch=0.0, target_yaw=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e892-4c57-4eb5-b293-065775805be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
