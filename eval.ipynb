{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370f3c67-da3e-489d-8a54-882f2aed8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load eval.py\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "\n",
    "from dataset.mpii_face_gaze_dataset import get_dataloaders\n",
    "from train import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import calc_angle_error, PitchYawHelper\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d364906e-0439-4ce4-bbaf-becbf9197e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a5cdd1-dcdd-4f29-8aa2-3286679ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration_lr(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    ‰ΩøÁî® Linear Regression ÂÅöË¶ñÁ∑öÂÅèÁßªÊ†°Ê≠£\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # ÈÅ∏ S ÂºµÂúñ‰ΩúÁÇ∫Ê†°Ê≠£Ë≥áÊñô\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Êì∑Âèñ calibration Ë≥áÊñôÁöÑ pred & label\n",
    "        preds, labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            label = d['label'].cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "        # Âü∑Ë°å Linear Regression Êì¨Âêà (pred -> label)\n",
    "        reg = LinearRegression().fit(preds, labels)\n",
    "\n",
    "        # Ê∏¨Ë©¶ÊôÇÂ•óÁî® regression Ê†°Ê≠£\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'], d['face'], d['right_eye'], d['left_eye']\n",
    "            ).squeeze(0).cpu().numpy()\n",
    "            corrected = reg.predict([pred])[0]\n",
    "            angle = calc_angle_error(\n",
    "                torch.tensor(corrected).unsqueeze(0).to(device),\n",
    "                d['label'].unsqueeze(0)\n",
    "            )\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"üìê Linear Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c540133-8e27-4300-8cb9-af07f3a48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_calibration(model, dataset, S=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    Ê®°Êì¨ S ÂºµÂúñÁï∂Ê†°Ê≠£Ë≥áÊñôÔºåÂ∞çÂâ©‰∏ãË≥áÊñôÊ∏¨Ë©¶„ÄÇ\n",
    "    Ê®°Âûã forward Êé•Êî∂Ê†ºÂºèÔºöFinalModel(person_idx, full_face, right_eye, left_eye)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            item = dataset[i]\n",
    "            data = {\n",
    "                'left_eye': item['left_eye_image'].unsqueeze(0).to(device),\n",
    "                'right_eye': item['right_eye_image'].unsqueeze(0).to(device),\n",
    "                'face': item['full_face_image'].unsqueeze(0).to(device),\n",
    "                'label': torch.tensor(\n",
    "                    [float(item['gaze_pitch']), float(item['gaze_yaw'])],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device),\n",
    "                'person_idx': torch.tensor([[item['person_idx']]]).to(device)  # shape [1, 1]\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "        # Step 1ÔºöÈÅ∏ S ÂºµÂúñÁï∂Ê†°Ê≠£Ë≥áÊñô\n",
    "        indices = np.random.choice(len(all_data), size=S, replace=False)\n",
    "        calibration_set = [all_data[i] for i in indices]\n",
    "        test_set = [all_data[i] for i in range(len(all_data)) if i not in indices]\n",
    "\n",
    "        # Step 2ÔºöË®àÁÆó bias\n",
    "        cal_outputs, cal_labels = [], []\n",
    "        for d in calibration_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0)\n",
    "            cal_outputs.append(pred)\n",
    "            cal_labels.append(d['label'])\n",
    "\n",
    "        bias = torch.stack(cal_labels).mean(dim=0) - torch.stack(cal_outputs).mean(dim=0)\n",
    "\n",
    "        # Step 3ÔºöÂ•óÁî® bias ÂÅöÊ∏¨Ë©¶\n",
    "        angle_errors = []\n",
    "        for d in test_set:\n",
    "            pred = model(\n",
    "                d['person_idx'],\n",
    "                d['face'],\n",
    "                d['right_eye'],\n",
    "                d['left_eye']\n",
    "            ).squeeze(0) + bias\n",
    "\n",
    "            angle = calc_angle_error(pred.unsqueeze(0), d['label'].unsqueeze(0))\n",
    "            angle_errors.append(angle.item())\n",
    "\n",
    "        mean_err = np.mean(angle_errors)\n",
    "        print(f\"üìê Calibration (S={S}): {mean_err:.2f} degrees\")\n",
    "        return mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87f414e-5956-4245-9688-cf91f9bf2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models/p00/p00_best-v28.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\gazegpu\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on persons [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "valid on person 0\n",
      "test on person 1\n",
      "len(dataset_train) 60784\n",
      "len(dataset_valid) 2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset_test) 2904\n",
      "Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181/181 [00:25<00:00,  7.21it/s]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "             Test metric                         DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   test/offset(k=0)/angular_error             3.6843724250793457\n",
      "        test/offset(k=0)/loss                0.0026730604004114866\n",
      "test/offset(k=128)/mean_angular_error         2.7850077686071395\n",
      "test/offset(k=128)/std_angular_error          0.02994585057951566\n",
      " test/offset(k=9)/mean_angular_error          2.9401812864780426\n",
      " test/offset(k=9)/std_angular_error           0.1896842254231117\n",
      "  test/offset(k=all)/angular_error            2.7732884883880615\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìê Least Squares (3D Vec) Calibration (S=1): 90.36 degrees\n",
      "üìê Least Squares (3D Vec) Calibration (S=5): 90.85 degrees\n",
      "üìê Least Squares (3D Vec) Calibration (S=9): 90.34 degrees\n",
      "üìê Least Squares (3D Vec) Calibration (S=16): 89.41 degrees\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ###ÈùûËÆäÂãïÂçÄÂ°ä\n",
    "    k = [1,5,9,16,32,64, 128]\n",
    "    adjust_slope = False\n",
    "    ###Â∞çÊáâ‰ΩúËÄÖË°®Ê†ºgrid calibration,Â¶ÇÊûúÊòØrandomÂ∞±Â°´true\n",
    "    grid_calibration_samples=False\n",
    "    batch_size =32\n",
    "    path_to_data = './data/mpiifacegaze_preprocessed'\n",
    "    \n",
    "    \n",
    "    ####ËÆäÂãïÂçÄÂ°ä\n",
    "    path_to_checkpoints = './saved_models/p00/p00_best-v28.ckpt'\n",
    "    person_idx = 1\n",
    "    validate_on_person = 0 \n",
    "    \n",
    "    seed_everything(42)\n",
    "\n",
    "    print(f\"{path_to_checkpoints}\")\n",
    "    \n",
    "    model = Model.load_from_checkpoint(path_to_checkpoints, k=[9, 128], adjust_slope=False, grid_calibration_samples=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        gpus=1,\n",
    "        benchmark=True,\n",
    "    )\n",
    "\n",
    "    _, _, test_dataloader = get_dataloaders(        path_to_data, \n",
    "        validate_on_person, \n",
    "        person_idx, \n",
    "        batch_size   \n",
    "    )\n",
    "     \n",
    "    trainer.test(model, test_dataloader)\n",
    "\n",
    "    ####################ÊãøÂá∫ test setÔºàÂñÆ‰∫∫ÂÆåÊï¥Ë≥áÊñôÔºâ\n",
    "    test_dataset = test_dataloader.dataset\n",
    "    #######################\n",
    "\n",
    "    simulate_calibration_ls(model, test_dataset, S=1)\n",
    "    simulate_calibration_ls(model, test_dataset, S=5)\n",
    "    simulate_calibration_ls(model, test_dataset, S=9)\n",
    "    simulate_calibration_ls(model, test_dataset, S=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e892-4c57-4eb5-b293-065775805be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
